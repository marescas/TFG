{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import math\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels Train\n",
    "tr_label_file = open(\"/Volumes/MARCOS E/PAN2018/train/es.txt\")\n",
    "labels_b = [author.split(\":::\") for author in tr_label_file.read().split(\"\\n\")]\n",
    "labels = {}\n",
    "for author in labels_b:\n",
    "    if len(author) > 1:\n",
    "        labels[author[0]] = author[1]\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels Test\n",
    "te_label_file = open(\"/Volumes/MARCOS E/PAN2018/test/es.txt\")\n",
    "labels_b = [author.split(\":::\") for author in te_label_file.read().split(\"\\n\")]\n",
    "labels_test = {}\n",
    "for author in labels_b:\n",
    "    if len(author) > 1:\n",
    "        labels_test[author[0]] = author[1]\n",
    "print(\"OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_caffe_models(prototxt,caffemodel):\n",
    "    \"\"\"\n",
    "    Carga de un modelo de redes neuronales profundas (Caffe) \n",
    "    Necesita la arquitectura de la red y los pesos de las neuronas\n",
    "    \"\"\"\n",
    "    net =cv2.dnn.readNetFromCaffe(prototxt,caffemodel)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Carga de un modelo HaarCascade pre-entrenado para detección de caras\n",
    "detector_caras = cv2.CascadeClassifier(\"frontdetector.xml\") \n",
    "gender_net = load_caffe_models(\"deploy_gender.prototxt\",\"gender_net.caffemodel\") #Detección de género con Caffe \n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "gender_list = ['Male', 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculaPorcentaje(dirname,labels):\n",
    "    directorios = [f for f in listdir(dirname)]\n",
    "    globalCorpus = []\n",
    "    globalLabels = []\n",
    "    imagenes_erroneas = 0\n",
    "    imagenes_totales = 0\n",
    "    #Recorremos los directorios\n",
    "    for directorio in directorios:\n",
    "        #Obtenemos la etiqueta asociada (Hombre o mujer)\n",
    "        etiqueta = labels.get(directorio)\n",
    "        corpusLocal = []\n",
    "        if  etiqueta != None:\n",
    "            imagenes = [f for f in listdir(dirname+\"/\"+directorio)] #Obtenemos las 10 imágenes por autor\n",
    "            imagenes_correctas = 0\n",
    "            #Recorremos cada imagen\n",
    "            for imagen in imagenes:\n",
    "                imagenes_totales+=1\n",
    "                try:\n",
    "                    image = cv2.imread(dirname+\"/\"+directorio+\"/\"+imagen) \n",
    "                    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY) #Transformamos la imagen a Blanco y negro\n",
    "                    #Aplicamos HaarCascade --> lista de caras\n",
    "                    caras = detector_caras.detectMultiScale(gray,1.5,5)\n",
    "                    if len(caras)>0:\n",
    "                        #Recorremos cada cara obteniendola para lanzarla contra la red neuronal\n",
    "                        for (x,y,w,h) in caras:\n",
    "                            face_img = image[y:y+h, x:x+w].copy()\n",
    "                            #Lanzamos la cara contra la red neuronal...\n",
    "                            blob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "                            gender_net.setInput(blob)\n",
    "                            gender_preds = gender_net.forward()\n",
    "                            #Obtenemos la clase más probable\n",
    "                            gender = gender_list[gender_preds[0].argmax()]\n",
    "                            corpusLocal.append(-1 if gender == \"Male\" else 1)\n",
    "                    imagenes_correctas+=1\n",
    "                except:\n",
    "                    imagenes_erroneas+=1\n",
    "            hombres = sum([1 for element in corpusLocal if element ==-1]) #número de hombres por autor\n",
    "            #porcentaje de hombre en las fotos del autor\n",
    "            globalCorpus.append(hombres/len(corpusLocal) if len(corpusLocal) > 0 else 0) \n",
    "            globalLabels.append(etiqueta)\n",
    "    print(\"Imagenes Erroneas: %d\" %imagenes_erroneas)         \n",
    "    print(len(globalLabels) ==len(globalCorpus))\n",
    "    return globalCorpus, globalLabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalCorpusTrain, globalLabelsTrain = calculaPorcentaje(\"/Volumes/MARCOS E/PAN2018/train/photo\",labels)\n",
    "globalCorpusTest, globalLabelsTest = calculaPorcentaje(\"/Volumes/MARCOS E/PAN2018/test/es/photo\",labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveObject(outputFile, representacion,etiquetas):\n",
    "    \"\"\"\n",
    "    Guardo la representación y las etiquetas ya que es muy costoso calcularlo\n",
    "    \"\"\"\n",
    "    with open(outputFile,\"wb\") as fh:\n",
    "        object = representacion, etiquetas\n",
    "        pickle.dump(object,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveObject(\"pcarasTrain\",globalCorpusTrain,globalLabelsTrain)\n",
    "saveObject(\"pcarasTest\",globalCorpusTest,globalLabelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def openfile(fileName):\n",
    "    \"\"\"\n",
    "    Dado el nombre de un fichero devuelve la representación y las etiquetas\n",
    "    \"\"\"\n",
    "    with open(fileName,\"rb\") as fh:\n",
    "        representacion,etiquetas = pickle.load(fh)\n",
    "    return etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cargamos los datos\n",
    "globalCorpusTrain, globalLabelsTrain = openfile(\"pcarasTrain\")\n",
    "globalCorpusTest, globalLabelsTest = openfile(\"pcarasTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intervalo95(p,datos):\n",
    "    \"\"\"\n",
    "    Calcula el intervalo al 95% \n",
    "    :param p: probabilidad de acierto\n",
    "    :param datos: numero de datos del conjunto de test\n",
    "    \"\"\"\n",
    "    e = 1.96*math.sqrt((p*(1-p))/datos)\n",
    "    s = \"[%.3f , %.3f]\" % (p-e,p+e)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(clasificador,xtrain,xlabels,bloques):\n",
    "    scores = cross_val_score(clasificador, xtrain, xlabels, cv=bloques, scoring='f1_macro')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs = [1,10,100,1000,10000]\n",
    "kernel= [\"linear\",\"rbf\"]\n",
    "res = \"c \\t \\t k \\t \\t Accuracy \\t \\t Inter95 \\n\"\n",
    "res += \"---------------------SVM--------------------------\\n\"\n",
    "for k in kernel:\n",
    "    for c in cs:\n",
    "        clf = svm.SVC(C = c,kernel=k)\n",
    "        media = cross_validation(clf,np.array(globalCorpusTrain).reshape((3000,1)),globalLabelsTrain,10)\n",
    "        clf.fit(np.array(globalCorpusTrain).reshape((3000,1)),globalLabelsTrain)\n",
    "        p = clf.score(np.array(globalCorpusTest).reshape((2200,1)),globalLabelsTest)\n",
    "        aux = \"%d \\t \\t  %s \\t \\t %.4f \\t \\t %s \\n\" % (c,k[0:3],p, intervalo95(p,len(globalLabelsTest)))\n",
    "        print(aux)\n",
    "        res+= aux\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [1,10,100,1000,10000,100000]\n",
    "res = \"c \\t \\t Accuracy \\t \\t Inter95 \\n\"\n",
    "res += \"---------------------Logistic--------------------------\\n\"\n",
    "for c in cs:\n",
    "    clf = LogisticRegression(C=c)\n",
    "    media = cross_validation(clf,np.array(globalCorpusTrain).reshape((3000,1)),globalLabelsTrain,10) \n",
    "    clf.fit(np.array(globalCorpusTrain).reshape((3000,1)),globalLabelsTrain)\n",
    "    p = clf.score(np.array(globalCorpusTest).reshape((2200,1)),globalLabelsTest)\n",
    "    aux = \"%d \\t \\t %.3f \\t \\t %s \\n\" %(c,p,intervalo95(p,len(globalLabelsTest)))\n",
    "    print(aux)\n",
    "    res+= aux\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
