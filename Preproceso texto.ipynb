{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from nltk.stem import SnowballStemmer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveObject(texto, labels, outputFile):\n",
    "    \"\"\"\n",
    "    Vuelca el preproceso del texto y las etiquetas en un fichero\n",
    "    \"\"\"\n",
    "    with open(outputFile,\"wb\") as fh:\n",
    "        object = (texto,labels)\n",
    "        pickle.dump(object,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Stemming(text):\n",
    "    \"\"\"\n",
    "    Devuelve el stemming de un determinado texto\n",
    "    \"\"\"\n",
    "    stemmer  = SnowballStemmer(\"spanish\")\n",
    "    textosalida = \" \".join([stemmer.stem(w) for w in text.split(\" \")])\n",
    "    return textosalida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_re = re.compile('\\W+')\n",
    "url_re = re.compile(\"https?://[^\\s]+\")\n",
    "hashtag_re = re.compile(\"#(\\w+)\")\n",
    "mention_re = re.compile(\"@(\\w+)\")\n",
    "def preprocessing(text):\n",
    "    \"\"\"\n",
    "    Realiza el preprocesado de un determinado texto:\n",
    "    1- sustituye las urls por la palabra <url>\n",
    "    2- sustituye los hashtags por la palabra <hashtag>\n",
    "    3- sustituye las menciones por la palabra <mencion>\n",
    "    4- sustituye los numeros por la palabra <numero>\n",
    "    \"\"\"\n",
    "    text_clean = url_re.sub(\"<url>\",text)\n",
    "    text_clean = hashtag_re.sub(\"<hashtag>\", text_clean)\n",
    "    text_clean = mention_re.sub(\"<mencion>\", text_clean)\n",
    "    text_clean =re.sub(\"\\d+\", \"<numero>\", text_clean)\n",
    "    #text_clean = clean_re.sub(\" \",text_clean).lower()\n",
    "    text_clean = text_clean.lower()\n",
    "    #text_clean = Stemming(text_clean)\n",
    "    \n",
    "    return text_clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readXML(filename):\n",
    "    \"\"\"\n",
    "    Dado el nombre de un fichero en formato XML:\n",
    "    obtiene el corpus de tweets (preprocesados)\n",
    "    Concatena todos los tweets con la etiqueta <FinTweet>\n",
    "    \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    i=0\n",
    "    tweets =root.find(\"documents\")\n",
    "    author = \" <FinTweet> \".join([tweet.text for tweet in tweets])\n",
    "    return preprocessing(author)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labels Train\n",
    "tr_label_file = open(\"/Volumes/MARCOS E/PAN2018/train/es.txt\")\n",
    "labels_b = [author.split(\":::\") for author in tr_label_file.read().split(\"\\n\")]\n",
    "labels = {}\n",
    "for author in labels_b:\n",
    "    if len(author) > 1:\n",
    "        labels[author[0]] = author[1]\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labels Test\n",
    "te_label_file = open(\"/Volumes/MARCOS E/PAN2018/test/es.txt\")\n",
    "labels_b = [author.split(\":::\") for author in te_label_file.read().split(\"\\n\")]\n",
    "labels_test = {}\n",
    "for author in labels_b:\n",
    "    if len(author) > 1:\n",
    "        labels_test[author[0]] = author[1]\n",
    "print(\"OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Corpus / Etiquetas Train\n",
    "dirTrain = \"/Volumes/MARCOS E/PAN2018/train/text\"\n",
    "filesTrain = [f for f in listdir(dirTrain)]\n",
    "globalCorpusTrain = []\n",
    "globalLabelsTrain = []\n",
    "for filename in filesTrain:\n",
    "    name =filename.split(\".\")\n",
    "    if labels.get(name[0]) is not None: #si existe un autor con el mismo nombre en es.txt\n",
    "        corpusLocal = readXML(dirTrain+\"/\"+filename)\n",
    "        globalCorpusTrain.append(corpusLocal)\n",
    "        globalLabelsTrain.append(-1 if labels[name[0]] == \"male\" else 1)\n",
    "print(\"Lectura train OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveObject(globalCorpusTrain,globalLabelsTrain,\"preproceso_train\")\n",
    "print(\"Preproceso del texto guardado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Corpus / Etiquetas Test\n",
    "dirTest = \"/Volumes/MARCOS E/PAN2018/test/es/text\"\n",
    "filesTrain = [f for f in listdir(dirTest)]\n",
    "globalCorpusTest = []\n",
    "globalLabelsTest = []\n",
    "for filename in filesTrain:\n",
    "    name =filename.split(\".\")\n",
    "    if labels_test.get(name[0]) is not None:\n",
    "        corpusLocal = readXML(dirTest+\"/\"+filename)\n",
    "        globalCorpusTest.append(corpusLocal)\n",
    "        globalLabelsTest.append(-1 if labels_test[name[0]] == \"male\" else 1)\n",
    "print(\"Lectura test OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveObject(globalCorpusTest,globalLabelsTest,\"preproceso_test\")\n",
    "print(\"Preproceso del texto guardado correctamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
