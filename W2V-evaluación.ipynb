{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def openfile(fileName):\n",
    "    \"\"\"\n",
    "    Dado el nombre de un fichero devuelve el corpus preprocesado y las etiquetas\n",
    "    \"\"\"\n",
    "    with open(fileName,\"rb\") as fh:\n",
    "        texto,etiquetas = pickle.load(fh)\n",
    "    return texto,etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveRep(representacion,etiquetas, outputFile):\n",
    "    \"\"\"\n",
    "    Vuelca la representación y las etiquetas en un fichero\n",
    "    \"\"\"\n",
    "    with open(outputFile,\"wb\") as fh:\n",
    "        object = representacion,etiquetas\n",
    "        pickle.dump(object,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un Word2Vec a partir de los tweets extraidos de Streamings de Twitter y corpus del PAN \n",
    "#CUESTA MUCHO TIEMPO DE COMPUTO ¡MEJOR COMENTARLO :/ !\n",
    "\n",
    "#data = pd.read_csv(\"datosParaWord2VecProcesado.csv\")\n",
    "#corpusWord2Vec = textoTrain\n",
    "#corpusToken = [x.split() for x in corpusWord2Vec]\n",
    "#corpusToken = [x.split() for x in data[\"Data\"] ]\n",
    "#model = Word2Vec(corpusToken, size=300, window=5, min_count=1, workers=2)\n",
    "print(\"modelo entrenado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cargamos el modelo pre-entrenado\n",
    "with open(\"word2vecmodel\",\"rb\") as fh:\n",
    "    word2vec = pickle.load(fh)\n",
    "word_vectors = word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.most_similar(\"politico\") #Palabras con un contexto similar a político"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textoTrain, etiquetasTrain = openfile(\"preproceso_train\")\n",
    "textoTest, etiquetasTest = openfile(\"preproceso_test\")\n",
    "print(\"Lectura de ficheros correcta. Documentos de train: %d Documentos de test: %d \" %(len(textoTrain),len(textoTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "corpusTrainw2v = []\n",
    "keysNoExistentes = 0\n",
    "documentosprocesados = 0\n",
    "for document in textoTrain:\n",
    "    #Por cada autor\n",
    "    wordlist = []\n",
    "    for word in document:\n",
    "        #obtenemos el embedding de cada una de las palabras\n",
    "        try:\n",
    "            wordlist.append(word_vectors[word].tolist()) #añadimos el embedding de cada palabra\n",
    "        except KeyError :\n",
    "            keysNoExistentes+=1\n",
    "    matrixmedia = np.matrix(wordlist)\n",
    "    corpusTrainw2v.append(matrixmedia.mean(0)) #computamos la media por columnas\n",
    "    documentosprocesados+=1\n",
    "    if documentosprocesados % 100 == 0:\n",
    "        print(\"Documentos procesados %d\" %documentosprocesados) \n",
    "print(\"Keys no existentes %d\" % keysNoExistentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una EDA valida para los algoritmos de aprendizaje TRAIN\n",
    "corpusW2VTrain = []\n",
    "for i in range(0,len(corpusTrainw2v)):\n",
    "    corpusW2VTrain.append(corpusTrainw2v[i].tolist()[0])\n",
    "print(\"Corpus Train OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "corpusTestw2v = []\n",
    "keysNoExistentes = 0\n",
    "documentosprocesados = 0\n",
    "for document in textoTest:\n",
    "    wordlist = []\n",
    "    for word in document:\n",
    "        try:\n",
    "            wordlist.append(word_vectors[word].tolist())\n",
    "        except KeyError :\n",
    "            keysNoExistentes+=1\n",
    "    matrixmedia = np.matrix(wordlist)\n",
    "    corpusTestw2v.append(matrixmedia.mean(0))\n",
    "    documentosprocesados+=1\n",
    "    if documentosprocesados % 100 == 0:\n",
    "        print(\"Documentos procesados %d\" %documentosprocesados) \n",
    "print(\"Keys no existentes %d\" % keysNoExistentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una EDA valida para los algoritmos de aprendizaje TEST\n",
    "corpusW2VTest = []\n",
    "for i in range(0,len(corpusTestw2v)):\n",
    "    corpusW2VTest.append(corpusTestw2v[i].tolist()[0])\n",
    "print(\"Corpus Test listo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(clasificador,xtrain,xlabels,bloques):\n",
    "    scores = cross_val_score(clasificador, xtrain, xlabels, cv=bloques, scoring='f1_macro')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intervalo95(p,datos):\n",
    "    \"\"\"\n",
    "    Calcula el intervalo al 95% \n",
    "    :param p: probabilidad de acierto\n",
    "    :param datos: numero de datos del conjunto de test\n",
    "    \"\"\"\n",
    "    e = 1.96*math.sqrt((p*(1-p))/datos)\n",
    "    s = \"[%.3f , %.3f]\" % (p-e,p+e)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [1,10,100,1000,10000]\n",
    "kernel= [\"linear\",\"rbf\"]\n",
    "res = \"c \\t \\t k \\t \\t Accuracy \\t \\t Inter95 \\n\"\n",
    "res += \"---------------------SVM--------------------------\\n\"\n",
    "for k in kernel:\n",
    "    for c in cs:\n",
    "        clf = svm.SVC(C = c,kernel=k)\n",
    "        clf.fit(corpusW2VTrain,etiquetasTrain)\n",
    "        #media = cross_validation(clf,corpusW2VTrain,etiquetasTrain,10)\n",
    "        p = clf.score(corpusW2VTest,etiquetasTest)\n",
    "        aux = \"%d \\t \\t  %s \\t \\t %.4f \\t \\t %s \\n\" % (c,k[0:3],p, intervalo95(p,len(etiquetasTest)))\n",
    "        print(aux)\n",
    "        res+= aux\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [1,10,100,1000,10000]\n",
    "res = \"c \\t \\t Accuracy \\t \\t Inter95 \\n\"\n",
    "res += \"---------------------Logistic--------------------------\\n\"\n",
    "for c in cs:\n",
    "    clf = LogisticRegression(C=c)\n",
    "    clf.fit(corpusW2VTrain,etiquetasTrain)\n",
    "    #media = cross_validation(clf,corpusW2VTrain,etiquetasTrain,10)\n",
    "    p = clf.score(corpusW2VTest,etiquetasTest)\n",
    "    aux = \"%d \\t \\t %.3f \\t \\t %s \\n\" %(c,p,intervalo95(p,len(etiquetasTest)))\n",
    "    print(aux)\n",
    "    res+= aux\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveRep(corpusW2VTrain,etiquetasTrain,\"w2vRepTrain\")\n",
    "saveRep(corpusW2VTest,etiquetasTest,\"w2vRepTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
